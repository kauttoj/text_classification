Name: Wei XuUniquename: weixu#######################################################Description of the initial method:Classification algorithm: Naive Bayes.Training dataset: all 26,000 documents in the “kaggle.training/“ folderTest dataset: all 6,000 documents in the “kaggle.test/” folderClassification accuracy from Kaggle: 0.79833My initial method is built on Naive Bayes classifier. The documents are tokenized using my method from assignment 1. In the training step, all 26, 000 training document are used to determine the vocabulary, and then the corresponding conditional probability is computed based on the token in the vocabulary. The percentage of each class is also computed. In the test step, each test document is tokenized in the same way in the training step. Based on the tokens we get for each test document, the probability that this document belongs to each class is computed and then compared to determine the prediction result.#######################################################Description of the changes made to improve the initial method:1. Naïve Bayes is a simple and also powerful method, but I want to use more complicated but also more powerful machine learning algorithm. So I change my machine learning algorithm to SVM (Support Vector Mahcine), which technically will give better performance2. The initial method using Naïve Bayes does not actually need to vectorize the documents. In my second method, I use vectorization method to compute the counting frequency of tokens and then use tf-idf weighting method to compute the document-term matrix. Each document is presented by a numeric vector.#######################################################Description of the final method:Classification algorithm: SVM with linear kernelTraining dataset: all 26,000 documents in the “kaggle.training/” folderTest dataset: all 6,000 documents in the “kaggle.test/” folder Classification accuracy from Kaggle: 0.81300 Resources used: 1. Python Scikit Learn Package2. TfidfVectorizer function from Scikit Learn Package3. SVM function from Scikit Learn Package4. GridSearchCV function from Scikit Learn PackageNote: Since I am using Scikit Learn package, before running my code of final method, please run “module load python” first in the terminal, so that Scikit Learn package can be normally imported, or you will get errors.My final method is built on SVM with linear kernel and tf-idf weighting vectorization. It gives better performance than my initial method using Naïve Bayes. In the training step, the documents are vectorized using TfidfVectorizer function, and we get the numeric training data matrix. In the test step, each test document is also vectorized using the same vectorizer in the training step, and then I input the numeric test vector to SVM algorithm to give the predict result.Besides, SVM algorithm with linear kernel needs one user-defined parameter C. The default value of C is 1.0. In order to improve the performance, I use Grid Search method to evaluate the training dataset on a range of different C values, so that it can give the best C value based on the training performance. Then this C value will be used on testing. The accuracy gets improved when using Grid Search to find the best C instead of using the default C=1.0.